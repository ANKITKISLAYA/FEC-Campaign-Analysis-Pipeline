{"cells": [{"cell_type": "markdown", "id": "0a5f00c9-0dab-4085-94fe-d32450bcb5ef", "metadata": {}, "source": "## Phase 2: Data Cleaning & Transformation"}, {"cell_type": "code", "execution_count": 1, "id": "1db319a3-819b-497e-9383-338a36110a1e", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, when, sum as _sum,  trim, lower, to_date, year, month, weekofyear, quarter, avg as _avg, countDistinct, to_date, upper, lit, regexp_replace\nfrom pyspark.sql.types import DoubleType, IntegerType, DateType, StringType, LongType"}, {"cell_type": "markdown", "id": "29d03b18-3267-45ca-90be-25bcbbaa41b4", "metadata": {}, "source": "#### Optimize based on configuration of cluster\n- **Workers (2)**\t 2 \u00d7 n2-standard-4 (4 vCPUs, 15 GB Memory each)\n- **Master**\t \u00d7 n2-standard-4\n- Total vCPUs\t12 (4\u00d73)\n- Total = 8 vCPUs and ~30 GB memory across workers"}, {"cell_type": "code", "execution_count": 2, "id": "05811cf5-8b7e-4ac1-8ee2-6467d61b4f16", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/13 14:24:51 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = (\n    SparkSession.builder\n    .appName(\"DataCleaningAndTransformation\")\n    .config(\"spark.sql.shuffle.partitions\", \"80\")               # Since 8 cores (2*4vCPU) , rule of thumb: 10 shuffle partitions per CPU core \n    .config(\"spark.executor.memory\", \"5g\")                      # memory per executor (per node 10gb memory assigned to executor out of 15gb,giving room for overhead)\n    .config(\"spark.driver.memory\", \"4g\")                        # Adjust if driver needs more, can be increased to 6g\n    .config(\"spark.executor.cores\", \"2\")                        # Good parallelism, 4 executor across cluster which avoids overloading one executor\n    .config(\"spark.dynamicAllocation.enabled\", \"true\")          # Useful for Dataproc\n    .getOrCreate()\n)"}, {"cell_type": "markdown", "id": "37e2f81e-a64d-4831-87dc-b109bbe97641", "metadata": {}, "source": "## Reading stored data in parquet format"}, {"cell_type": "code", "execution_count": 3, "id": "6e592251-76d7-4e14-8b6f-b31d97e5313d", "metadata": {"tags": []}, "outputs": [], "source": "# Path to file stored in parquet format\nbronze_path = 'gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/bronze/'"}, {"cell_type": "code", "execution_count": 4, "id": "e8ee39a2-d9ca-470b-9954-220367b7ee81", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Read Data from parquet\n\n# All candidates Data\nAllCand_df = spark.read.parquet(bronze_path + 'AllCand_df')\n\n# Any transaction from one committee to another Data\nTranOneComToAno_df = spark.read.parquet(bronze_path + 'TranOneComToAno_df')\n\n# Candidate-committee linkages\nCanComLink_df = spark.read.parquet(bronze_path + 'CanComLink_df')\n\n# Contributions by individuals\nConByInd_df = spark.read.parquet(bronze_path + 'ConByInd_df')\n\n# Contributions from committees to candidates & independent expenditure\nConFromComToCanIndExpen_df = spark.read.parquet(bronze_path + 'ConFromComToCanIndExpen_df') \n\n# House Senate current campaigns\nHouSenCurCam_df = spark.read.parquet(bronze_path + 'HouSenCurCam_df')\n\n# Operating expenditures\nOpEx_df = spark.read.parquet(bronze_path + 'OpEx_df')\n\n# PAC summary\nPacSum_df = spark.read.parquet(bronze_path + 'PacSum_df')\n\n# Candidate master\nCandMast_df = spark.read.parquet(bronze_path + 'CandMast_df')\n\n# Commitee master\nCommMast_df = spark.read.parquet(bronze_path + 'CommMast_df')"}, {"cell_type": "markdown", "id": "270218e3-00b8-44bc-a502-93065c40a1d4", "metadata": {}, "source": "## 1. Cleaning \u2013 handle missing values, removing trailing spaces etc."}, {"cell_type": "markdown", "id": "befa783d-a313-4215-ab35-889626590a39", "metadata": {}, "source": "### Check Null values count in each column"}, {"cell_type": "code", "execution_count": 5, "id": "1e962541-47e0-42ba-b36f-57e51316ba21", "metadata": {"tags": []}, "outputs": [], "source": "# Function to check null counts in dataframe\ndef null_counts (df):\n    null_counts_df = df.select( [_sum( when(col(c).isNull() , 1).otherwise(0) ).alias(c) \n                              for c in df.columns] )\n    return null_counts_df"}, {"cell_type": "markdown", "id": "155cb852-3bfd-4bbe-a8ae-cdfc14ec7694", "metadata": {}, "source": "### Basic cleaning function which trims spaces and replaces \"\", \"NA\", \"N/A\" with None"}, {"cell_type": "code", "execution_count": 6, "id": "2c72fbf9-0e5f-4c05-9f2b-17ce5d133dcb", "metadata": {"tags": []}, "outputs": [], "source": "def base_clean(df):\n    # Trim all string columns\n    for c in df.columns:\n        df = df.withColumn(c, when(col(c).isNotNull() & (df[c].cast(\"string\").isNotNull()), trim(col(c))).otherwise(col(c)))\n    \n    # Replace \"\", \"NA\", \"N/A\" with None\n    for c in df.columns:\n        df = df.withColumn(c, when((col(c).isin('', 'NA', 'N/A')), None).otherwise(col(c)))\n    \n    return df"}, {"cell_type": "markdown", "id": "a4e9edab-fadb-4b79-bc62-afd37f63b985", "metadata": {}, "source": "### Cleaning All candidates df\n1. Fill nulls for CAND_ICI with 'U' (Unknown)\n2. Fill nulls for CAND_PTY_AFFILIATION with 'UNK' \n3. Drop legacy or mostly-null columns which will not be used for analysis"}, {"cell_type": "code", "execution_count": 7, "id": "ec93ea02-8347-434b-b219-715c02388d8b", "metadata": {"tags": []}, "outputs": [], "source": "\ndef clean_AllCand_df(df):\n    # Fill nulls for CAND_ICI with 'U' (Unknown)\n    df = df.withColumn(\"CAND_ICI\", when(col(\"CAND_ICI\").isNull(), \"U\").otherwise(col(\"CAND_ICI\")))\n\n    # Fill nulls for CAND_PTY_AFFILIATION with 'UNK'\n    df = df.withColumn(\"CAND_PTY_AFFILIATION\", when(col(\"CAND_PTY_AFFILIATION\").isNull(), \"UNK\").otherwise(col(\"CAND_PTY_AFFILIATION\")))\n\n    # Drop legacy or mostly-null columns\n    df = df.drop(\"SPEC_ELECTION\", \"PRIM_ELECTION\", \"RUN_ELECTION\", \"GEN_ELECTION\", \"GEN_ELECTION_PRECENT\")\n\n    return df\n\n"}, {"cell_type": "markdown", "id": "694cfa7f-c1c9-4eda-8ee7-3d444171fcc7", "metadata": {}, "source": "### Cleaning Any transaction from one committee to another df\n1. Drop legacy columns not required for further analysis\n2. Handle nulls with default values or flags \n"}, {"cell_type": "code", "execution_count": 8, "id": "19400000-5541-4ace-9477-eb076e570b24", "metadata": {"tags": []}, "outputs": [], "source": "# Cleaning any transaction from one committee to another df\ndef clean_TranOneComToAno_df(df):\n    \n    # Drop legacy columns that have too many nulls\n    cols_to_drop = ['EMPLOYER', 'OCCUPATION', 'OTHER_ID', 'MEMO_CD', 'MEMO_TEXT', 'SUB_ID']\n    df = df.drop(*cols_to_drop)\n    \n    # Handle nulls with default values or flags\n    df = df.fillna({\n        \"TRANSACTION_PGI\": \"U0000\",   # Unknown election year\n        \"ENTITY_TP\": \"UNK\",          # Unknown entity\n        \"NAME\": \"Unknown Name\",\n        \"CITY\": \"Unknown City\",\n        \"STATE\": \"NA\",\n        \"ZIP_CODE\": \"00000\",\n        \"TRANSACTION_DT\": \"01011900\",  # Dummy old date \n        \"TRAN_ID\": \"UNKNOWN\"\n    })\n    \n    return df\n"}, {"cell_type": "markdown", "id": "c33b7411-9c48-42cb-a4af-981adeb03a20", "metadata": {}, "source": "### Cleaning Candidate-committee linkage df\n1. Trim all string columns\n2. Drop duplicates \n"}, {"cell_type": "code", "execution_count": 9, "id": "965e9cf0-eacd-4098-ba61-43454a7cde88", "metadata": {"tags": []}, "outputs": [], "source": "def clean_CanComLink_df(df):\n    # Trim all string columns\n    for column in df.columns:\n        df = df.withColumn(column, trim(col(column)))\n        \n    # Drop duplicates\n    df = df.dropDuplicates()\n    \n    return df"}, {"cell_type": "markdown", "id": "5724a0a7-9a31-4bf9-9d74-2f8d24e12fb3", "metadata": {"tags": []}, "source": "### Cleaning Contributions by individuals df\n1. Filter out rows missing truly critical information\n2. Keep only individual contributions \n3. Drop legacy columns\n4. Replace nulls using fillna"}, {"cell_type": "code", "execution_count": 10, "id": "42dbf489-8a0a-4078-b419-12d121573a2f", "metadata": {"tags": []}, "outputs": [], "source": "# Cleaning Contributions by individuals df\ndef clean_ConByInd_df(df):\n    \n    # Filter out rows missing truly critical information\n    df = df.filter(col('TRANSACTION_AMT').isNotNull())    \n    df = df.filter(col('TRANSACTION_DT').isNotNull())\n    df = df.filter(col('SUB_ID').isNotNull())\n\n    # Keep only individual contributions\n    df = df.filter(col('OTHER_ID').isNull())\n\n    # Drop legacy columns\n    cols_to_drop = ['OTHER_ID', 'MEMO_CD', 'MEMO_TEXT']\n    df = df.drop(*cols_to_drop)\n\n    # Replace nulls using fillna\n    df = df.fillna({\n        'TRANSACTION_PGI': 'O',\n        'ENTITY_TP': 'IND', # null likely indicates an unrecorded individual contributor\n        'NAME': 'UNKNOWN',\n        'CITY': 'UNKNOWN',\n        'STATE': 'NA',\n        'ZIP_CODE': '00000',\n        'EMPLOYER': 'UNKNOWN',\n        'OCCUPATION': 'UNKNOWN',\n        'TRAN_ID': 'MISSING',\n        'FILE_NUM': 0\n    })\n\n    return df\n"}, {"cell_type": "markdown", "id": "4a6d7298-c31b-45fe-a045-89fb790b9ac8", "metadata": {}, "source": "### Cleaning Contributions from committees to candidates & independent expenditures df\n1. Filter Columns where OTHER_ID is notNull since Null indicates contributions from individuals\n2. Filter Columns where CAND_ID is notNUll \n3. Replace nulls using fillna\n4. Drop rarely used or high-null columns"}, {"cell_type": "code", "execution_count": 11, "id": "2a09c354-f333-4a24-bb53-9add2588d5b9", "metadata": {"tags": []}, "outputs": [], "source": "def clean_ConFromComToCanIndExpen_df(df):\n    # Filter Columns where OTHER_ID is notNull since Null \n    # indicates contributions from individuals\n    df = df.filter(col('OTHER_ID').isNotNull())\n    \n    # Filter Columns where CAND_ID is notNUll\n    df = df.filter(col('CAND_ID').isNotNull())\n  \n    # Replace nulls using fillna\n    df = df.fillna({\n        'TRANSACTION_PGI': 'UKN',\n        'ENTITY_TP' : 'COM', # the contributor is typically a committee here in com to cand contr\n        'NAME': 'UNKNOWN',\n        'CITY': 'UNKNOWN',\n        'STATE': 'NA',\n        'ZIP_CODE': '00000',\n        'TRANSACTION_DT': '12319999',\n        'TRAN_ID': 'MISSING',\n    })\n    \n    # Drop rarely used or high-null columns\n    cols_to_drop = ['EMPLOYER', 'OCCUPATION', 'OTHER_ID', 'MEMO_CD', 'MEMO_TEXT']\n    df = df.drop(*cols_to_drop)\n        \n    return df\n"}, {"cell_type": "markdown", "id": "4c75f3d4-0c33-41ff-9aca-06e64eebc093", "metadata": {}, "source": "### Cleaning Current campaigns for House and Senate file df\n1. Fill NUll value for col CAND_ICI as U (Unkown)\n2. Fill nulls in CVG_END_DT with default date\n3. Drop rarely used or high-null columns"}, {"cell_type": "code", "execution_count": 12, "id": "1ab6b5d0-11d2-4065-b58e-11895c3541a1", "metadata": {"tags": []}, "outputs": [], "source": "def clean_HouSenCurCam_df(df):\n    # Fill NUll value for col CAND_ICI as U (Unkown)\n    df = df.fillna({'CAND_ICI': 'U'})\n    \n    # Fill nulls in CVG_END_DT with default date\n    df = df.fillna({'CVG_END_DT': '12/31/9999'})\n    \n    # Drop rarely used or high-null columns\n    cols_to_drop = ['SPEC_ELECTION', 'PRIM_ELECTION', 'RUN_ELECTION', 'GEN_ELECTION', 'GEN_ELECTION_PRECENT']\n    df = df.drop(*cols_to_drop)\n        \n    return df\n"}, {"cell_type": "markdown", "id": "e765ba72-e631-47b0-a5cd-6606191f1692", "metadata": {}, "source": "### Cleaning Operating expenditures df\n1. Drop irrelevant or mostly-null columns\n2. Handle Null values"}, {"cell_type": "code", "execution_count": 13, "id": "80c88375-c69b-4e60-82f2-5b6f893aba66", "metadata": {"tags": []}, "outputs": [], "source": "def clean_OpEx_df(df):\n    # Drop irrelevant or mostly-null columns\n    cols_to_drop = ['MEMO_CD', 'MEMO_TEXT', 'BACK_REF_TRAN_ID', 'extra_column']\n    df = df.drop(*cols_to_drop)\n    \n    # Handle Null values\n    fill_values = {\n    \"NAME\": \"UNKNOWN\",\n    \"CITY\": \"UNKNOWN\",\n    \"STATE\": \"UNK\",\n    \"ZIP_CODE\": \"00000\",\n    \"TRANSACTION_DT\": \"12/31/9999\",\n    \"TRANSACTION_PGI\": \"N/A\",\n    \"PURPOSE\": \"UNSPECIFIED\",\n    \"CATEGORY\": \"MISC\",\n    \"CATEGORY_DESC\": \"MISCELLANEOUS\",\n    \"ENTITY_TP\": \"UNKNOWN\"\n    }\n    df = df.fillna(fill_values)\n\n    return df"}, {"cell_type": "markdown", "id": "80bff95f-aa15-4725-ae35-32a8406b09fa", "metadata": {}, "source": "### Cleaning PAC and party summary df\n1. Drop legacy columns\n2. Fill nulls in numeric columns with 0.0"}, {"cell_type": "code", "execution_count": 14, "id": "be4c3607-298a-4d11-a8d7-b6656baa9880", "metadata": {"tags": []}, "outputs": [], "source": "def clean_PacSum_df(df):\n    # Drop legacy columns\n    legacy_cols = [\n        \"CMTE_DSGN\",\"CAND_CONTRIB\", \"CAND_LOANS\", \"TTL_LOANS_RECEIVED\", \"CAND_LOAN_REPAY\",\n        \"OTHER_POL_CMTE_REFUNDS\", \"INDV_REFUNDS\", \"NONFED_TRANS_RECEIVED\", \n        \"NONFED_SHARE_EXP\"\n    ]\n    df = df.drop(*legacy_cols)\n\n    # Fill nulls in numeric columns with 0.0\n    numeric_cols = [\n        \"TTL_RECEIPTS\", \"TRANS_FROM_AFF\", \"INDV_CONTRIB\", \"OTHER_POL_CMTE_CONTRIB\",\n        \"TTL_DISB\", \"TRANF_TO_AFF\", \"LOAN_REPAY\", \"COH_BOP\", \"COH_COP\", \"DEBTS_OWED_BY\",\n        \"CONTRIB_TO_OTHER_CMTE\", \"IND_EXP\", \"PTY_COORD_EXP\"\n    ]\n    for col_name in numeric_cols:\n        df = df.withColumn(col_name, when(col(col_name).isNull(), lit(\"0.0\")).otherwise(col(col_name)))\n\n    # Handle nulls in date\n    df = df.withColumn(\"CVG_END_DT\", when(col(\"CVG_END_DT\").isNull(), lit(\"12/31/9999\")).otherwise(col(\"CVG_END_DT\")))\n\n    return df"}, {"cell_type": "markdown", "id": "e5eda134-b528-4759-be9a-f9620bfc389c", "metadata": {"tags": []}, "source": "### Cleaning Candidate master df\n1. Drop redundant or rarely useful columns\n2. Handle nulls / empty values"}, {"cell_type": "code", "execution_count": 15, "id": "38b8b1e2-e098-4d7d-87da-784dcf52b709", "metadata": {"tags": []}, "outputs": [], "source": "\ndef clean_CandMast_df(df):\n    # Drop redundant or rarely useful columns\n    df = df.drop(\"CAND_ST1\", \"CAND_ST2\", \"CAND_PCC\")\n\n    # Handle nulls / empty values\n    df = df.fillna({\n        \"CAND_PTY_AFFILIATION\": \"UNK\", # Unknown party\n        \"CAND_OFFICE_DISTRICT\": \"-1\",  # -1 means non-district-based\n        \"CAND_ICI\": \"U\",              # U = Unknown status\n        \"CAND_CITY\": \"UNKNOWN\",                \n        \"CAND_ST\": \"NA\",                       \n        \"CAND_ZIP\": \"00000\"\n    })\n    \n    return df\n"}, {"cell_type": "markdown", "id": "b86a382e-e3a1-4a70-90f3-8d356b6031cc", "metadata": {}, "source": "### Cleaning Committee master df\n1. Drop mostly null or redundant address fields\n2. Fill nulls with appropriate default values"}, {"cell_type": "code", "execution_count": 16, "id": "636e46e8-e551-4160-918e-75e06ce993b3", "metadata": {"tags": []}, "outputs": [], "source": "def clean_CommMast_df(df):\n    # Drop mostly null or redundant address fields\n    df = df.drop(\"CMTE_ST1\", \"CMTE_ST2\")\n\n    # Fill nulls with appropriate default values\n    df = df.fillna({\n        \"CMTE_NM\": \"UNKNOWN_COMMITTEE\",\n        \"TRES_NM\": \"UNKNOWN_TREASURER\",\n        \"CMTE_CITY\": \"UNKNOWN_CITY\",\n        \"CMTE_ST\": \"NA\",\n        \"CMTE_ZIP\": \"00000\",\n        \"CMTE_DSGN\": \"U\",  # Unknown designation\n        \"CMTE_TP\": \"U\",    # Unknown type\n        \"CMTE_PTY_AFFILIATION\": \"OTH\",  # Other\n        \"ORG_TP\": \"N/A\",\n        \"CONNECTED_ORG_NM\": \"NONE\",\n        \"CAND_ID\": \"UNLINKED\"\n    })\n\n    return df\n"}, {"cell_type": "markdown", "id": "9e37521a-7c19-4017-8d4c-e2e326f37715", "metadata": {}, "source": "## 2. Typecasting \u2013 convert columns to correct data types"}, {"cell_type": "markdown", "id": "588eac6c-0205-4c05-b12b-c0f9e2a67913", "metadata": {}, "source": "### Typecasting All candidates df"}, {"cell_type": "code", "execution_count": 17, "id": "13c8309e-3b3c-4c3f-9327-63339df7b0db", "metadata": {"tags": []}, "outputs": [], "source": "\ndef typecast_AllCand_df(df):\n\n    # List of columns to cast as DoubleType\n    double_cols = [\n        \"TTL_RECEIPTS\", \"TRANS_FROM_AUTH\", \"TTL_DISB\", \"TRANS_TO_AUTH\",\n        \"COH_BOP\", \"COH_COP\", \"CAND_CONTRIB\", \"CAND_LOANS\", \"OTHER_LOANS\",\n        \"CAND_LOAN_REPAY\", \"OTHER_LOAN_REPAY\", \"DEBTS_OWED_BY\",\n        \"TTL_INDIV_CONTRIB\", \"OTHER_POL_CMTE_CONTRIB\", \"POL_PTY_CONTRIB\",\n        \"INDIV_REFUNDS\", \"CMTE_REFUNDS\"\n    ]\n\n    # Cast numeric columns to Double\n    for col_name in double_cols:\n        df = df.withColumn(col_name, col(col_name).cast(DoubleType()))\n\n    # Cast CVG_END_DT to DateType (assuming MM/dd/yyyy format)\n    df = df.withColumn(\"CVG_END_DT\", to_date(col(\"CVG_END_DT\"), \"MM/dd/yyyy\"))\n\n    return df\n"}, {"cell_type": "markdown", "id": "f4f1e104-4ea5-4bd1-be80-63d60e07fa2e", "metadata": {}, "source": "### Typecasting Any transaction from one committee to another df"}, {"cell_type": "code", "execution_count": 18, "id": "f61d2ae1-ea19-4d91-b803-bd73c11f732f", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_TranOneComToAno_df(df):\n    \n    df = df.withColumn(\"TRANSACTION_AMT\", col(\"TRANSACTION_AMT\").cast(DoubleType()))\n    df = df.withColumn(\"FILE_NUM\", col(\"FILE_NUM\").cast(IntegerType()))\n    \n    # Convert date format (assuming MMDDYYYY or similar)\n    df = df.withColumn(\"TRANSACTION_DT\", to_date(col(\"TRANSACTION_DT\"), \"MMddyyyy\"))\n    \n    return df"}, {"cell_type": "markdown", "id": "30d1d5af-a3d6-4598-99eb-6ced340221b3", "metadata": {}, "source": "### Typecasting Candidate-committee linkage df"}, {"cell_type": "code", "execution_count": 19, "id": "d0148f67-9723-4ab3-ad41-2d6b2250034c", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_CanComLink_df(df):\n    df = df.withColumn(\"CAND_ELECTION_YR\", col(\"CAND_ELECTION_YR\").cast(IntegerType())) \\\n        .withColumn(\"FEC_ELECTION_YR\", col(\"FEC_ELECTION_YR\").cast(IntegerType())) \\\n        .withColumn(\"LINKAGE_ID\", col(\"LINKAGE_ID\").cast(IntegerType()))    \n    return df "}, {"cell_type": "markdown", "id": "9ca124a2-70c4-41c5-84e7-474b6d1b1d03", "metadata": {}, "source": "### Typecasting Contributions by individuals df"}, {"cell_type": "code", "execution_count": 20, "id": "998d9bd1-8cad-4803-818d-5a39399d2310", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_ConByInd_df(df):\n    df = df.withColumn(\"TRANSACTION_AMT\", col(\"TRANSACTION_AMT\").cast(DoubleType())) \\\n        .withColumn(\"ZIP_CODE\", col(\"ZIP_CODE\").cast(StringType())) \\\n        .withColumn(\"TRANSACTION_DT\", to_date(col(\"TRANSACTION_DT\"), \"MMddyyyy\")) \\\n        .withColumn(\"FILE_NUM\", col(\"FILE_NUM\").cast(IntegerType())) \\\n        .withColumn(\"SUB_ID\", col(\"SUB_ID\").cast(LongType()))\n    return df"}, {"cell_type": "markdown", "id": "b98f3eed-b310-4d03-b120-b90ba5df0500", "metadata": {}, "source": "### Typecasting Contributions from committees to candidates and independent expenditures df"}, {"cell_type": "code", "execution_count": 21, "id": "f2a8d7a0-003f-44d9-bdee-a3c8258ec94b", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_ConFromComToCanIndExpen_df(df):\n    df = df.withColumn(\"TRANSACTION_AMT\", col(\"TRANSACTION_AMT\").cast(DoubleType())) \\\n        .withColumn(\"FILE_NUM\", col(\"FILE_NUM\").cast(IntegerType())) \\\n        .withColumn(\"SUB_ID\", col(\"SUB_ID\").cast(LongType())) \\\n        .withColumn(\"TRANSACTION_DT\", to_date(col(\"TRANSACTION_DT\"), \"MMddyyyy\")) \\\n        .withColumn(\"ZIP_CODE\", col(\"ZIP_CODE\").cast(StringType()))\n    return df"}, {"cell_type": "markdown", "id": "62fdda4e-e6e6-4184-a6ad-8646241d66c5", "metadata": {}, "source": "### Typecasting Current campaigns for House and Senate file df"}, {"cell_type": "code", "execution_count": 22, "id": "2fc5c942-9f78-4c98-83cd-f518f5a44660", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_HouSenCurCam_df(df):\n    # Financial fields\n    money_cols = [\n        \"TTL_RECEIPTS\", \"TRANS_FROM_AUTH\", \"TTL_DISB\", \"TRANS_TO_AUTH\", \"COH_BOP\", \"COH_COP\",\n        \"CAND_CONTRIB\", \"CAND_LOANS\", \"OTHER_LOANS\", \"CAND_LOAN_REPAY\", \"OTHER_LOAN_REPAY\",\n        \"DEBTS_OWED_BY\", \"TTL_INDIV_CONTRIB\", \"OTHER_POL_CMTE_CONTRIB\", \"POL_PTY_CONTRIB\",\n        \"INDIV_REFUNDS\", \"CMTE_REFUNDS\"\n    ]\n    for col_name in money_cols:\n        df = df.withColumn(col_name, df[col_name].cast(DoubleType()))\n    \n    df = df.withColumn(\"CVG_END_DT\", to_date(df[\"CVG_END_DT\"], \"MM/dd/yyyy\"))\n    \n    return df"}, {"cell_type": "markdown", "id": "02919d4e-5f93-40c6-9489-2c4bd293c6ef", "metadata": {}, "source": "### Typecasting Operating expenditures df"}, {"cell_type": "code", "execution_count": 23, "id": "1431af65-ae5c-4fbd-b169-6ab0c1c73d80", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_OpEx_df(df):\n    \n    df = df.withColumn(\"TRANSACTION_AMT\", col(\"TRANSACTION_AMT\").cast(DoubleType())) \\\n        .withColumn(\"SUB_ID\", col(\"SUB_ID\").cast(LongType())) \\\n        .withColumn(\"FILE_NUM\", col(\"FILE_NUM\").cast(IntegerType())) \\\n        .withColumn(\"RPT_YR\", col(\"RPT_YR\").cast(IntegerType())) \\\n        .withColumn(\"TRANSACTION_DT\", to_date(col(\"TRANSACTION_DT\"), \"MM/dd/yyyy\")) \\\n        .withColumn(\"ZIP_CODE\", col(\"ZIP_CODE\").cast(\"string\"))\n\n    return df"}, {"cell_type": "markdown", "id": "7165cec1-fb62-46a2-8203-0c4f7ffe6599", "metadata": {}, "source": "### Typecasting PAC and party summary df"}, {"cell_type": "code", "execution_count": 24, "id": "6f3bacdf-27af-4586-a6e6-1215b2f6ed0e", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_PacSum_df(df):\n    # numeric cols\n    numeric_cols = [\n        \"TTL_RECEIPTS\", \"TRANS_FROM_AFF\", \"INDV_CONTRIB\", \"OTHER_POL_CMTE_CONTRIB\",\n        \"TTL_DISB\", \"TRANF_TO_AFF\", \"LOAN_REPAY\", \"COH_BOP\", \"COH_COP\", \"DEBTS_OWED_BY\",\n        \"CONTRIB_TO_OTHER_CMTE\", \"IND_EXP\", \"PTY_COORD_EXP\"\n    ]\n    for col_name in numeric_cols:\n        df = df.withColumn(col_name, df[col_name].cast(DoubleType()))\n    \n    df = df.withColumn(\"CVG_END_DT\", to_date(df[\"CVG_END_DT\"], \"MM/dd/yyyy\"))\n    \n    return df"}, {"cell_type": "markdown", "id": "c7976edd-bce5-48a0-ad1f-c3886c6104f5", "metadata": {}, "source": "### Typecasting Candidate master df"}, {"cell_type": "code", "execution_count": 25, "id": "9f0c2bca-b506-46fd-a17a-8ad60b0d3925", "metadata": {"tags": []}, "outputs": [], "source": "def typecast_CandMast_df(df):\n    df = df.withColumn(\"CAND_ELECTION_YR\", col(\"CAND_ELECTION_YR\").cast(IntegerType())) \\\n        .withColumn(\"CAND_OFFICE_DISTRICT\", col(\"CAND_OFFICE_DISTRICT\").cast(IntegerType())) \\\n        .withColumn(\"CAND_ZIP\", col(\"CAND_ZIP\").cast(StringType()))\n    return df"}, {"cell_type": "markdown", "id": "43f7c926-88d9-4714-9c24-8cd6ba7f36cb", "metadata": {}, "source": "## 3. Feature Engineering \u2013 derive new features, aggregate, normalize\n"}, {"cell_type": "markdown", "id": "c1490ec9-5438-4eff-966f-9368eeb308e3", "metadata": {}, "source": "### Feature Engineering for All candidates df\n1. Extract Year, Month and Quarter from end coverage date and normalise state and district\n2. Adjusting TTL_RECEIPTS & TTL_DISB for intra-committee transfers\n3. Creating new features for Financial Behavior like net_cash_position, cash_delta, self_sufficiency_ratio, loan_dependence_ratio etc.\n4. Aggregate Data by geography like candidate state and district"}, {"cell_type": "code", "execution_count": 26, "id": "e83bcf58-add1-48c8-8076-2ff62b66c1da", "metadata": {"tags": []}, "outputs": [], "source": "def features_AllCand_df(df):\n\n    # Extract Year, Month and Quarter from end coverage date and normalise state and district\n    df = df.withColumn('CVG_END_DT', to_date('CVG_END_DT','MM/dd/yyyy')) \\\n            .withColumn(\"YEAR\", year('CVG_END_DT')) \\\n            .withColumn(\"MONTH\", month('CVG_END_DT')) \\\n            .withColumn(\"QUARTER\", quarter('CVG_END_DT')) \\\n            .withColumn(\"CAND_OFFICE_ST\", upper(col(\"CAND_OFFICE_ST\"))) \\\n            .withColumn(\"CAND_OFFICE_DISTRICT\", upper(col(\"CAND_OFFICE_DISTRICT\")))\n    \n    # Adjusting for intra-committee transfers\n    df = df.withColumn(\"TTL_RECEIPTS\", col(\"TTL_RECEIPTS\") - col(\"TRANS_FROM_AUTH\")) \\\n                   .withColumn(\"TTL_DISB\", col(\"TTL_DISB\") - col(\"TRANS_TO_AUTH\"))\n    \n    # Financial Behavior Feature Engineering\n    df = df.withColumn(\"net_cash_position\", col(\"TTL_RECEIPTS\") - col(\"TTL_DISB\")) \\\n    .withColumn(\"cash_delta\", col(\"COH_COP\") - col(\"COH_BOP\")) \\\n    .withColumn(\"self_sufficiency_ratio\", when(col(\"TTL_RECEIPTS\") != 0, col(\"CAND_CONTRIB\") / col(\"TTL_RECEIPTS\")).otherwise(0)) \\\n    .withColumn(\"loan_dependence_ratio\", when(col(\"TTL_RECEIPTS\") != 0, \n        (col(\"CAND_LOANS\") + col(\"OTHER_LOANS\")) / col(\"TTL_RECEIPTS\")).otherwise(0)) \\\n    .withColumn(\"refund_ratio\", when(col(\"TTL_RECEIPTS\") != 0, \n        (col(\"INDIV_REFUNDS\") + col(\"CMTE_REFUNDS\")) / col(\"TTL_RECEIPTS\")).otherwise(0)) \\\n    .withColumn(\"indiv_contrib_ratio\", when(col(\"TTL_RECEIPTS\") != 0, \n        col(\"TTL_INDIV_CONTRIB\") / col(\"TTL_RECEIPTS\")).otherwise(0))\n    return df\n\ndef geo_AllCand_df(df):\n    \"\"\"\n    Aggregate Data by geography.\n    \"\"\"\n    # Aggregation by candidate state and district\n    geo_agg_df = df.groupBy(\"CAND_OFFICE_ST\", \"CAND_OFFICE_DISTRICT\").agg(\n    _sum(\"TTL_RECEIPTS\").alias(\"total_receipts\"),\n    _sum(\"TTL_DISB\").alias(\"total_disbursements\"),\n    _sum(\"CAND_CONTRIB\").alias(\"total_candidate_contributions\"),\n    _sum(\"CAND_LOANS\").alias(\"total_candidate_loans\"),\n    _sum(\"OTHER_LOANS\").alias(\"total_other_loans\"),\n    _sum(\"INDIV_REFUNDS\").alias(\"total_indiv_refunds\"),\n    _sum(\"CMTE_REFUNDS\").alias(\"total_cmte_refunds\"),\n    _avg(\"TTL_RECEIPTS\").alias(\"avg_receipts_per_candidate\"),\n    _avg(\"TTL_DISB\").alias(\"avg_disbursements_per_candidate\")\n    )\n    return geo_agg_df"}, {"cell_type": "markdown", "id": "5176e532-3e8f-4a96-9174-b71f951bae15", "metadata": {"tags": []}, "source": "### Feature Engineering for Any transaction from one committee to another df\n1. Normalise state, transaction type and entity type\n2. Total transaction amount by state aggreagation\n3. Total contributions by entity type aggreagation\n"}, {"cell_type": "code", "execution_count": 27, "id": "ba4eba5b-0a81-4d1e-9ec5-e154df25293c", "metadata": {"tags": []}, "outputs": [], "source": "\ndef features_TranOneComToAno_df(df):\n    \n    # Normalize \n    df = df.withColumn(\"TRANSACTION_TP\", upper(col(\"TRANSACTION_TP\"))) \\\n        .withColumn(\"ENTITY_TP\", upper(col(\"ENTITY_TP\"))) \\\n        .withColumn(\"STATE\", upper(col(\"STATE\")))\n\n    # Total transaction amount by state\n    agg_by_state = df.groupBy(\"STATE\").agg(\n        _sum(\"TRANSACTION_AMT\").alias(\"TOTAL_AMT_STATE\")\n    )\n\n    # Total contributions by entity type\n    agg_by_entity = df.groupBy(\"ENTITY_TP\").agg(\n        _sum(\"TRANSACTION_AMT\").alias(\"TOTAL_AMT_ENTITY\"),\n        countDistinct(\"NAME\").alias(\"UNIQUE_CONTRIBUTORS\")\n    )\n\n    return df, agg_by_state, agg_by_entity\n"}, {"cell_type": "markdown", "id": "9abdbf33-08ab-4889-a0de-0578bb8da056", "metadata": {}, "source": "### Feature Engineering for Candidate-committee linkage df\n1. Add committee type descriptions\n2. Add committee designation categories (P=Principal, A=Authorized, etc.)\n"}, {"cell_type": "code", "execution_count": 28, "id": "ea8f7e92-7fd0-4b34-a5cd-9dd30a5ee468", "metadata": {"tags": []}, "outputs": [], "source": "\ndef features_CanComLink_df(df):\n    # Add committee type descriptions\n    df = df.withColumn(\"CMTE_TP_DESC\", \n                       when(col(\"CMTE_TP\") == \"P\", \"Presidential\")\n                      .when(col(\"CMTE_TP\") == \"H\", \"House\")\n                      .when(col(\"CMTE_TP\") == \"S\", \"Senate\")\n                      .when(col(\"CMTE_TP\") == \"X\", \"Independent Expenditure\")\n                      .otherwise(\"Other\"))\n    # Add committee designation categories (P=Principal, A=Authorized, etc.)\n    df = df.withColumn(\"CMTE_DSGN_DESC\", \n                       when(col(\"CMTE_DSGN\") == \"P\", \"Principal Campaign Committee\")\n                      .when(col(\"CMTE_DSGN\") == \"A\", \"Authorized Committee\")\n                      .when(col(\"CMTE_DSGN\") == \"J\", \"Joint Fundraiser\")\n                      .when(col(\"CMTE_DSGN\") == \"U\", \"Unauthorized\")\n                      .otherwise(\"Other\"))\n    \n    return df\n"}, {"cell_type": "markdown", "id": "b24a927c-649c-4319-aab9-f90374b87cab", "metadata": {}, "source": "### Feature Engineering for Contributions by individuals df\n1. Extract year, month, week\n2. Normalize state\n3. Normalize donor names by removing middle name"}, {"cell_type": "code", "execution_count": 29, "id": "ef104dee-2647-4d96-8f8e-2b6eeaefd4c8", "metadata": {"tags": []}, "outputs": [], "source": "def features_ConByInd_df(df):\n    \n    # Extract year, month, week and normalize State\n    df = df.withColumn(\"YEAR\", year(col(\"TRANSACTION_DT\"))) \\\n           .withColumn(\"MONTH\", month(col(\"TRANSACTION_DT\"))) \\\n           .withColumn(\"WEEK\", weekofyear(col(\"TRANSACTION_DT\"))) \\\n           .withColumn(\"STATE\", upper(col(\"STATE\")))  # Normalize state names\n\n    # Normalize donor names by removing middle name\n    df = df.withColumn(\"NAME\", regexp_replace(\"NAME\", r\"\\s+[A-Z]\\.$\", \"\"))\n    \n    return df"}, {"cell_type": "markdown", "id": "373320f7-cec7-42de-8d34-0440f5cc8a4a", "metadata": {"tags": []}, "source": "### Feature Engineering for Contributions from committees to candidates df\n\n1. Extract year, month, weekofyear\n2. Normalize state, entity and transaction type\n"}, {"cell_type": "code", "execution_count": 30, "id": "30d80a42-0d5f-4482-8577-c4c6d30d37dd", "metadata": {"tags": []}, "outputs": [], "source": "def features_ConFromComToCanIndExpen_df(df):\n\n    # Extract year, month, week and normalize State\n    df = df.withColumn(\"YEAR\", year(col(\"TRANSACTION_DT\"))) \\\n        .withColumn(\"MONTH\", month(col(\"TRANSACTION_DT\"))) \\\n        .withColumn(\"WEEK\", weekofyear(col(\"TRANSACTION_DT\"))) \\\n        .withColumn(\"STATE\", upper(col(\"STATE\"))) \\\n        .withColumn(\"ENTITY_TP\", upper(col(\"ENTITY_TP\"))) \\\n        .withColumn(\"TRANSACTION_TP\", upper(col(\"TRANSACTION_TP\")))\n    \n    return df\n"}, {"cell_type": "markdown", "id": "6424c1c6-5218-43b3-aaf2-c6116250089d", "metadata": {"tags": []}, "source": "### Feature Engineering for Current campaigns for House and Senate df\n\n1. Create Feature Total loans, repay, contributions and net reciepts\n"}, {"cell_type": "code", "execution_count": 31, "id": "00c6730b-f09b-44a7-8d75-74adbdf3a0b1", "metadata": {"tags": []}, "outputs": [], "source": "def features_HouSenCurCam_df(df):\n    \n    # Create Feature Total loans, repay, contributions and net reciepts\n    df = df.withColumn(\"TOTAL_LOANS\", col(\"CAND_LOANS\") + col(\"OTHER_LOANS\")) \\\n        .withColumn(\"TOTAL_REPAY\", col(\"CAND_LOAN_REPAY\") + col(\"OTHER_LOAN_REPAY\")) \\\n        .withColumn(\"NET_RECEIPTS\", col(\"TTL_RECEIPTS\") - col(\"TTL_DISB\")) \\\n        .withColumn(\"TOTAL_CONTRIB\", col(\"TTL_INDIV_CONTRIB\") + col(\"OTHER_POL_CMTE_CONTRIB\") + col(\"POL_PTY_CONTRIB\"))\n    \n    return df"}, {"cell_type": "markdown", "id": "82b6cf76-6348-4453-9433-2ed8f114f96f", "metadata": {}, "source": "### Feature Engineering for Operating expenditures df\n1. Extract features YEAR and MONTH and normalise STATE , CATEGORY, \n   CATEGORY_DESC, ENTITY_TP in upper case\n"}, {"cell_type": "code", "execution_count": 32, "id": "5bfc8f03-cdc4-4b1b-b44c-784a0c7725ae", "metadata": {"tags": []}, "outputs": [], "source": "def features_OpEx_df(df):\n    \n    # Extract features YEAR and MONTH and normalise STATE , CATEGORY, \n    # CATEGORY_DESC, ENTITY_TP in upper case\n    df = df.withColumn(\"YEAR\", year(col(\"TRANSACTION_DT\"))) \\\n        .withColumn(\"MONTH\", month(col(\"TRANSACTION_DT\"))) \\\n        .withColumn(\"STATE\", upper(col(\"STATE\"))) \\\n        .withColumn(\"CATEGORY\", upper(col(\"CATEGORY\"))) \\\n        .withColumn(\"CATEGORY_DESC\", upper(col(\"CATEGORY_DESC\"))) \\\n        .withColumn(\"ENTITY_TP\", upper(col(\"ENTITY_TP\")))\n    return df"}, {"cell_type": "markdown", "id": "23582b06-2dec-429d-84a3-461d794530b5", "metadata": {}, "source": "### Feature Engineering for PAC and party summary df\n1. Calculating net cash flow, Contribution ratios, Running balances, Year extraction\n"}, {"cell_type": "code", "execution_count": 33, "id": "1670ba88-979a-4b80-8126-6e4793fb0a7d", "metadata": {"tags": []}, "outputs": [], "source": "def features_PacSum_df(df):\n    \n        # calculating net cash flow, Contribution ratios, Running balances, Year extraction\n        df = df.withColumn(\"NET_CASH_FLOW\", col(\"TTL_RECEIPTS\") - col(\"TTL_DISB\"))\n        df = df.withColumn(\n            \"INDV_CONTRIB_RATIO\",\n            when( col(\"TTL_RECEIPTS\") !=0, col(\"INDV_CONTRIB\")/col(\"TTL_RECEIPTS\") ).otherwise(0)\n        )\n        df = df.withColumn(\"YEAR\", year(col(\"CVG_END_DT\")))\n        return df"}, {"cell_type": "markdown", "id": "f47fe168-25ff-4d99-895b-26db90f33c73", "metadata": {}, "source": "### Feature Engineering for Candidate master df\n1. Create flags and normalized versions \n2. Map CAND_ICI (Incumbent/Challenger/Open Seat) \n"}, {"cell_type": "code", "execution_count": 34, "id": "363d9591-1a6d-474a-88e4-86f30c7ad132", "metadata": {"tags": []}, "outputs": [], "source": "def features_CandMast_df(df):\n\n    # Create flags and normalized versions\n    # Map CAND_ICI (Incumbent/Challenger/Open Seat) \n    df = df .withColumn(\"CAND_OFFICE\", upper(col(\"CAND_OFFICE\"))) \\\n        .withColumn(\"CAND_PTY_AFFILIATION\", upper(col(\"CAND_PTY_AFFILIATION\"))) \\\n        .withColumn(\"IS_INCUMBENT\", when(col(\"CAND_ICI\") == \"I\", 1).otherwise(0)) \\\n        .withColumn(\"IS_CHALLENGER\", when(col(\"CAND_ICI\") == \"C\", 1).otherwise(0)) \\\n        .withColumn(\"IS_OPEN_SEAT\", when(col(\"CAND_ICI\") == \"O\", 1).otherwise(0)) \n    return df"}, {"cell_type": "markdown", "id": "371da9ce-9f77-4f6f-b550-022590109fe3", "metadata": {}, "source": "### Feature Engineering for Committee master df\n1. Flags for committee type and designation\n2. Normalize party names\n3. Flag candidate-linked committees\n"}, {"cell_type": "code", "execution_count": 35, "id": "68d85fc5-3950-4f18-9fdd-821c2ffdb0fd", "metadata": {"tags": []}, "outputs": [], "source": "def features_CommMast_df(df):\n    \n    # Flags for committee type and designation\n    # Normalize party names\n    # Flag candidate-linked committees\n    df = df.withColumn(\"CMTE_TP\", upper(col(\"CMTE_TP\"))) \\\n        .withColumn(\"CMTE_PTY_AFFILIATION\", upper(col(\"CMTE_PTY_AFFILIATION\"))) \\\n        .withColumn(\"IS_CAND_LINKED\", when(col(\"CAND_ID\").isNotNull(), 1).otherwise(0)) \\\n        .withColumn(\"IS_AUTH_CMTE\", when(col(\"CMTE_DSGN\") == \"A\", 1).otherwise(0)) \\\n        .withColumn(\"IS_PAC\", when(col(\"CMTE_TP\").isin(\"Q\", \"N\", \"O\", \"U\"), 1).otherwise(0)) \\\n        .withColumn(\"IS_PARTY_CMTE\", when(col(\"CMTE_TP\") == \"Y\", 1).otherwise(0))\n    return df\n"}, {"cell_type": "markdown", "id": "d0ae6977-087e-43e6-8032-28bc8f813f20", "metadata": {}, "source": "## 4. Write processed data to parquet format in processed directory\n\nbase_path = \"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver\""}, {"cell_type": "code", "execution_count": 36, "id": "fc0c1a50-6720-493b-b6e4-4915f5c0ee27", "metadata": {"tags": []}, "outputs": [], "source": "def write_df_to_parquet(df, file_name, base_path=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver\"):\n    \"\"\"\n    Writes a Spark DataFrame to the specified GCS path in Parquet format.\n\n    Args:\n        df (DataFrame): Spark DataFrame to write.\n        file_name (str): Folder name (like table name) for Parquet output.\n        base_path (str): Base GCS path where data should be stored.\n    \"\"\"\n    output_path = f\"{base_path}/{file_name}\"\n    # write file in parquet in overwrite mode\n    # Snappy compression for efficient storage \n    # and faster read/write with Parquet   \n    df.write \\\n    .mode(\"overwrite\") \\\n    .option(\"compression\", \"snappy\") \\\n    .parquet(output_path) \n    \n    print(f\"Data written to: {output_path}\")\n"}, {"cell_type": "markdown", "id": "4ec40e1a-a961-4964-9233-ce4a40acc412", "metadata": {}, "source": "## Run cleaning and transformation pipeline and save data in processed layer"}, {"cell_type": "markdown", "id": "7f573004-a36e-4d67-963e-4f3734971edc", "metadata": {"tags": []}, "source": "### For All candidates df"}, {"cell_type": "code", "execution_count": 37, "id": "226eddb8-fa2e-4f0a-9139-0f07df17ce3f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/13 14:25:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"}, {"name": "stdout", "output_type": "stream", "text": "AllCand_df cached\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/AllCand_df\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/AllCand_geoAgg_df\nAllCand_df uncached\n"}], "source": "# All candidates\n\n# Clean data\nAllCand_df = base_clean(AllCand_df)\nAllCand_df = clean_AllCand_df(AllCand_df)\n\n# Type cast\nAllCand_df = typecast_AllCand_df(AllCand_df)\n\n# Feature Engineering\nAllCand_df = features_AllCand_df(AllCand_df)\n\n# Cache since AllCand_df reused in aggregation\nAllCand_df = AllCand_df.cache()\nprint(\"AllCand_df cached\")\n\n# Derived AllCand_geoAgg_df using cached df above\nAllCand_geoAgg_df = geo_AllCand_df(AllCand_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(AllCand_df,'AllCand_df')\nwrite_df_to_parquet(AllCand_geoAgg_df,'AllCand_geoAgg_df')\n\n# Uncache after writing to free memory\nAllCand_df.unpersist()\nprint(\"AllCand_df uncached\")\n"}, {"cell_type": "code", "execution_count": 38, "id": "143b0f4b-2305-4493-ad3a-bef2f1d22500", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CAND_ID: string (nullable = true)\n |-- CAND_NAME: string (nullable = true)\n |-- CAND_ICI: string (nullable = true)\n |-- PTY_CD: string (nullable = true)\n |-- CAND_PTY_AFFILIATION: string (nullable = true)\n |-- TTL_RECEIPTS: double (nullable = true)\n |-- TRANS_FROM_AUTH: double (nullable = true)\n |-- TTL_DISB: double (nullable = true)\n |-- TRANS_TO_AUTH: double (nullable = true)\n |-- COH_BOP: double (nullable = true)\n |-- COH_COP: double (nullable = true)\n |-- CAND_CONTRIB: double (nullable = true)\n |-- CAND_LOANS: double (nullable = true)\n |-- OTHER_LOANS: double (nullable = true)\n |-- CAND_LOAN_REPAY: double (nullable = true)\n |-- OTHER_LOAN_REPAY: double (nullable = true)\n |-- DEBTS_OWED_BY: double (nullable = true)\n |-- TTL_INDIV_CONTRIB: double (nullable = true)\n |-- CAND_OFFICE_ST: string (nullable = true)\n |-- CAND_OFFICE_DISTRICT: string (nullable = true)\n |-- OTHER_POL_CMTE_CONTRIB: double (nullable = true)\n |-- POL_PTY_CONTRIB: double (nullable = true)\n |-- CVG_END_DT: date (nullable = true)\n |-- INDIV_REFUNDS: double (nullable = true)\n |-- CMTE_REFUNDS: double (nullable = true)\n |-- YEAR: integer (nullable = true)\n |-- MONTH: integer (nullable = true)\n |-- QUARTER: integer (nullable = true)\n |-- net_cash_position: double (nullable = true)\n |-- cash_delta: double (nullable = true)\n |-- self_sufficiency_ratio: double (nullable = true)\n |-- loan_dependence_ratio: double (nullable = true)\n |-- refund_ratio: double (nullable = true)\n |-- indiv_contrib_ratio: double (nullable = true)\n\n+-------+---------+--------+------+--------------------+------------+---------------+--------+-------------+-------+-------+------------+----------+-----------+---------------+----------------+-------------+-----------------+--------------+--------------------+----------------------+---------------+----------+-------------+------------+----+-----+-------+-----------------+----------+----------------------+---------------------+------------+-------------------+\n|CAND_ID|CAND_NAME|CAND_ICI|PTY_CD|CAND_PTY_AFFILIATION|TTL_RECEIPTS|TRANS_FROM_AUTH|TTL_DISB|TRANS_TO_AUTH|COH_BOP|COH_COP|CAND_CONTRIB|CAND_LOANS|OTHER_LOANS|CAND_LOAN_REPAY|OTHER_LOAN_REPAY|DEBTS_OWED_BY|TTL_INDIV_CONTRIB|CAND_OFFICE_ST|CAND_OFFICE_DISTRICT|OTHER_POL_CMTE_CONTRIB|POL_PTY_CONTRIB|CVG_END_DT|INDIV_REFUNDS|CMTE_REFUNDS|YEAR|MONTH|QUARTER|net_cash_position|cash_delta|self_sufficiency_ratio|loan_dependence_ratio|refund_ratio|indiv_contrib_ratio|\n+-------+---------+--------+------+--------------------+------------+---------------+--------+-------------+-------+-------+------------+----------+-----------+---------------+----------------+-------------+-----------------+--------------+--------------------+----------------------+---------------+----------+-------------+------------+----+-----+-------+-----------------+----------+----------------------+---------------------+------------+-------------------+\n|      0|        0|       0|     0|                   0|           0|              0|       0|            0|      0|      0|           0|         0|          0|              0|               0|            0|                0|             0|                   0|                     0|              0|         0|            0|           0|   0|    0|      0|                0|         0|                     0|                    0|           0|                  0|\n+-------+---------+--------+------+--------------------+------------+---------------+--------+-------------+-------+-------+------------+----------+-----------+---------------+----------------+-------------+-----------------+--------------+--------------------+----------------------+---------------+----------+-------------+------------+----+-----+-------+-----------------+----------+----------------------+---------------------+------------+-------------------+\n\n"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/AllCand_df\"\nAllCand_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nAllCand_df.printSchema()\n\n# Check for null values\nnull_counts(AllCand_df).show()"}, {"cell_type": "markdown", "id": "c5b60602-f37f-416b-a068-267a028973b2", "metadata": {}, "source": "### For Any transaction from one committee to another df"}, {"cell_type": "code", "execution_count": 39, "id": "ebfa3804-e730-427e-8109-7e212dfa609e", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/TranOneComToAno_df\n"}], "source": "# Any transaction from one committee to another\n\n# Clean data\nTranOneComToAno_df = base_clean(TranOneComToAno_df)\nTranOneComToAno_df = clean_TranOneComToAno_df(TranOneComToAno_df)\n\n#Type cast\nTranOneComToAno_df = typecast_TranOneComToAno_df(TranOneComToAno_df)\n\n# Feature Engineering\nTranOneComToAno_df, agg_by_state, agg_by_entity = features_TranOneComToAno_df(TranOneComToAno_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(TranOneComToAno_df,'TranOneComToAno_df')\n"}, {"cell_type": "code", "execution_count": 40, "id": "c56b9a58-f1c5-47b2-8d4d-b61cf3263ee0", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+---------------+\n|STATE|TOTAL_AMT_STATE|\n+-----+---------------+\n|   IL|   3.22336839E8|\n|   AZ|   1.32964588E8|\n|   KS|    6.3710138E7|\n|   LA|    8.1493663E7|\n|   KY|    6.1464421E7|\n+-----+---------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 25:==============================================>           (4 + 1) / 5]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+----------------+-------------------+\n|ENTITY_TP|TOTAL_AMT_ENTITY|UNIQUE_CONTRIBUTORS|\n+---------+----------------+-------------------+\n|      CCM|   1.561849791E9|               4896|\n|      UNK|     2.5480294E7|               1352|\n|      PAC|   1.638461975E9|              14283|\n|      IND|   1.550589473E9|            1154734|\n|      ORG|   4.202744081E9|               7070|\n+---------+----------------+-------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Print result of aggregation by state and entity\nagg_by_state.show(5)\nagg_by_entity.show(5)"}, {"cell_type": "code", "execution_count": 41, "id": "06ada504-4dbf-427a-be3f-1981aa8553d0", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CMTE_ID: string (nullable = true)\n |-- AMNDT_IND: string (nullable = true)\n |-- RPT_TP: string (nullable = true)\n |-- TRANSACTION_PGI: string (nullable = true)\n |-- IMAGE_NUM: string (nullable = true)\n |-- TRANSACTION_TP: string (nullable = true)\n |-- ENTITY_TP: string (nullable = true)\n |-- NAME: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- STATE: string (nullable = true)\n |-- ZIP_CODE: string (nullable = true)\n |-- TRANSACTION_DT: date (nullable = true)\n |-- TRANSACTION_AMT: double (nullable = true)\n |-- TRAN_ID: string (nullable = true)\n |-- FILE_NUM: integer (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 30:===========================================>              (3 + 1) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------------+---------------+-------+--------+\n|CMTE_ID|AMNDT_IND|RPT_TP|TRANSACTION_PGI|IMAGE_NUM|TRANSACTION_TP|ENTITY_TP|NAME|CITY|STATE|ZIP_CODE|TRANSACTION_DT|TRANSACTION_AMT|TRAN_ID|FILE_NUM|\n+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------------+---------------+-------+--------+\n|      0|        0|     0|              0|        0|             0|        0|   0|   0|    0|       0|             0|              0|      0|       0|\n+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------------+---------------+-------+--------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/TranOneComToAno_df\"\nTranOneComToAno_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nTranOneComToAno_df.printSchema()\n\n# Check for null values\nnull_counts(TranOneComToAno_df).show()\n"}, {"cell_type": "markdown", "id": "96a2c3db-7fb1-41af-89c2-267986378274", "metadata": {}, "source": "### For Candidate-committee linkages df"}, {"cell_type": "code", "execution_count": 42, "id": "5200ba96-0535-4e7b-9c1a-104ba2862136", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/CanComLink_df\n"}], "source": "# Candidate-committee linkages\n\n# Clean data\nCanComLink_df = base_clean(CanComLink_df)\nCanComLink_df = clean_CanComLink_df(CanComLink_df)\n\n#Type cast\nCanComLink_df = typecast_CanComLink_df(CanComLink_df)\n\n# Feature Engineering\nCanComLink_df = features_CanComLink_df(CanComLink_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(CanComLink_df,'CanComLink_df')\n"}, {"cell_type": "code", "execution_count": 43, "id": "baca34c7-0be6-4b3b-b7f2-494210dbf826", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CAND_ID: string (nullable = true)\n |-- CAND_ELECTION_YR: integer (nullable = true)\n |-- FEC_ELECTION_YR: integer (nullable = true)\n |-- CMTE_ID: string (nullable = true)\n |-- CMTE_TP: string (nullable = true)\n |-- CMTE_DSGN: string (nullable = true)\n |-- LINKAGE_ID: integer (nullable = true)\n |-- CMTE_TP_DESC: string (nullable = true)\n |-- CMTE_DSGN_DESC: string (nullable = true)\n\n+-------+----------------+---------------+-------+-------+---------+----------+------------+--------------+\n|CAND_ID|CAND_ELECTION_YR|FEC_ELECTION_YR|CMTE_ID|CMTE_TP|CMTE_DSGN|LINKAGE_ID|CMTE_TP_DESC|CMTE_DSGN_DESC|\n+-------+----------------+---------------+-------+-------+---------+----------+------------+--------------+\n|      0|               0|              0|      0|      0|        0|         0|           0|             0|\n+-------+----------------+---------------+-------+-------+---------+----------+------------+--------------+\n\n"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/CanComLink_df\"\nCanComLink_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nCanComLink_df.printSchema()\n\n# Check for null values\nnull_counts(CanComLink_df).show()"}, {"cell_type": "markdown", "id": "d563bce7-b49a-4757-9db0-3b20ecfd9bd8", "metadata": {"tags": []}, "source": "### For Contributions by individuals df"}, {"cell_type": "code", "execution_count": 44, "id": "e8c76ed5-a03f-4e79-a988-ad1240b7c6f7", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/ConByInd_df\n"}], "source": "# Contributions by individuals\n\n# Clean data\nConByInd_df = base_clean(ConByInd_df)\nConByInd_df = clean_ConByInd_df(ConByInd_df)\n\n#Type cast\nConByInd_df = typecast_ConByInd_df(ConByInd_df)\n\n# Feature Engineering\nConByInd_df = features_ConByInd_df(ConByInd_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(ConByInd_df,'ConByInd_df')\n"}, {"cell_type": "code", "execution_count": 45, "id": "bb1a742a-0f7c-4e07-8b5c-6403d3c23b82", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CMTE_ID: string (nullable = true)\n |-- AMNDT_IND: string (nullable = true)\n |-- RPT_TP: string (nullable = true)\n |-- TRANSACTION_PGI: string (nullable = true)\n |-- IMAGE_NUM: string (nullable = true)\n |-- TRANSACTION_TP: string (nullable = true)\n |-- ENTITY_TP: string (nullable = true)\n |-- NAME: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- STATE: string (nullable = true)\n |-- ZIP_CODE: string (nullable = true)\n |-- EMPLOYER: string (nullable = true)\n |-- OCCUPATION: string (nullable = true)\n |-- TRANSACTION_DT: date (nullable = true)\n |-- TRANSACTION_AMT: double (nullable = true)\n |-- TRAN_ID: string (nullable = true)\n |-- FILE_NUM: integer (nullable = true)\n |-- SUB_ID: long (nullable = true)\n |-- YEAR: integer (nullable = true)\n |-- MONTH: integer (nullable = true)\n |-- WEEK: integer (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 42:===================================================>    (12 + 1) / 13]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------+----------+--------------+---------------+-------+--------+------+----+-----+----+\n|CMTE_ID|AMNDT_IND|RPT_TP|TRANSACTION_PGI|IMAGE_NUM|TRANSACTION_TP|ENTITY_TP|NAME|CITY|STATE|ZIP_CODE|EMPLOYER|OCCUPATION|TRANSACTION_DT|TRANSACTION_AMT|TRAN_ID|FILE_NUM|SUB_ID|YEAR|MONTH|WEEK|\n+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------+----------+--------------+---------------+-------+--------+------+----+-----+----+\n|      0|        0|     0|              0|        0|             0|        0|   0|   0|    0|       0|       0|         0|             0|              0|      0|       0|     0|   0|    0|   0|\n+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------+----------+--------------+---------------+-------+--------+------+----+-----+----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/ConByInd_df\"\nConByInd_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nConByInd_df.printSchema()\n\n# Check for null values\nnull_counts(ConByInd_df).show()"}, {"cell_type": "markdown", "id": "3e3a743d-2f8e-4027-aa7a-a96f5ea57737", "metadata": {}, "source": "### For Contributions from committees to candidates & independent expenditure df"}, {"cell_type": "code", "execution_count": 46, "id": "2e88a1bf-aea8-44f5-a18a-6b2a9085b9d3", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/ConFromComToCanIndExpen_df\n"}], "source": "# Contributions from committees to candidates & independent expenditure\n\n# Clean data\nConFromComToCanIndExpen_df = base_clean(ConFromComToCanIndExpen_df)\nConFromComToCanIndExpen_df = clean_ConFromComToCanIndExpen_df(ConFromComToCanIndExpen_df)\n\n#Type cast\nConFromComToCanIndExpen_df = typecast_ConFromComToCanIndExpen_df(ConFromComToCanIndExpen_df)\n\n# Feature Engineering\nConFromComToCanIndExpen_df = features_ConFromComToCanIndExpen_df(ConFromComToCanIndExpen_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(ConFromComToCanIndExpen_df,'ConFromComToCanIndExpen_df')\n"}, {"cell_type": "code", "execution_count": 47, "id": "77446d81-feba-4a75-b6f6-374e307772df", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CMTE_ID: string (nullable = true)\n |-- AMNDT_IND: string (nullable = true)\n |-- RPT_TP: string (nullable = true)\n |-- TRANSACTION_PGI: string (nullable = true)\n |-- IMAGE_NUM: string (nullable = true)\n |-- TRANSACTION_TP: string (nullable = true)\n |-- ENTITY_TP: string (nullable = true)\n |-- NAME: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- STATE: string (nullable = true)\n |-- ZIP_CODE: string (nullable = true)\n |-- TRANSACTION_DT: date (nullable = true)\n |-- TRANSACTION_AMT: double (nullable = true)\n |-- CAND_ID: string (nullable = true)\n |-- TRAN_ID: string (nullable = true)\n |-- FILE_NUM: integer (nullable = true)\n |-- SUB_ID: long (nullable = true)\n |-- YEAR: integer (nullable = true)\n |-- MONTH: integer (nullable = true)\n |-- WEEK: integer (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 47:==============>                                           (1 + 3) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------------+---------------+-------+-------+--------+------+----+-----+----+\n|CMTE_ID|AMNDT_IND|RPT_TP|TRANSACTION_PGI|IMAGE_NUM|TRANSACTION_TP|ENTITY_TP|NAME|CITY|STATE|ZIP_CODE|TRANSACTION_DT|TRANSACTION_AMT|CAND_ID|TRAN_ID|FILE_NUM|SUB_ID|YEAR|MONTH|WEEK|\n+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------------+---------------+-------+-------+--------+------+----+-----+----+\n|      0|        0|     0|              0|        0|             0|        0|   0|   0|    0|       0|             0|              0|      0|      0|       0|     0|   0|    0|   0|\n+-------+---------+------+---------------+---------+--------------+---------+----+----+-----+--------+--------------+---------------+-------+-------+--------+------+----+-----+----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/ConFromComToCanIndExpen_df\"\nConFromComToCanIndExpen_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nConFromComToCanIndExpen_df.printSchema()\n\n# Check for null values\nnull_counts(ConFromComToCanIndExpen_df).show()"}, {"cell_type": "markdown", "id": "10af26eb-e79e-4c39-9990-238cf0b581d8", "metadata": {}, "source": "### For House Senate current campaigns df"}, {"cell_type": "code", "execution_count": 48, "id": "1eda180a-a792-46f6-aa61-a6b088050b9b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/HouSenCurCam_df\n"}], "source": "# House Senate current campaigns\n\n# Clean data\nHouSenCurCam_df = base_clean(HouSenCurCam_df)\nHouSenCurCam_df = clean_HouSenCurCam_df(HouSenCurCam_df)\n\n#Type cast\nHouSenCurCam_df = typecast_HouSenCurCam_df(HouSenCurCam_df)\n\n# Feature Engineering\nHouSenCurCam_df = features_HouSenCurCam_df(HouSenCurCam_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(HouSenCurCam_df,'HouSenCurCam_df')\n"}, {"cell_type": "code", "execution_count": 49, "id": "4ea63b11-0d93-4833-9395-dfd23e428f4e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CAND_ID: string (nullable = true)\n |-- CAND_NAME: string (nullable = true)\n |-- CAND_ICI: string (nullable = true)\n |-- PTY_CD: string (nullable = true)\n |-- CAND_PTY_AFFILIATION: string (nullable = true)\n |-- TTL_RECEIPTS: double (nullable = true)\n |-- TRANS_FROM_AUTH: double (nullable = true)\n |-- TTL_DISB: double (nullable = true)\n |-- TRANS_TO_AUTH: double (nullable = true)\n |-- COH_BOP: double (nullable = true)\n |-- COH_COP: double (nullable = true)\n |-- CAND_CONTRIB: double (nullable = true)\n |-- CAND_LOANS: double (nullable = true)\n |-- OTHER_LOANS: double (nullable = true)\n |-- CAND_LOAN_REPAY: double (nullable = true)\n |-- OTHER_LOAN_REPAY: double (nullable = true)\n |-- DEBTS_OWED_BY: double (nullable = true)\n |-- TTL_INDIV_CONTRIB: double (nullable = true)\n |-- CAND_OFFICE_ST: string (nullable = true)\n |-- CAND_OFFICE_DISTRICT: string (nullable = true)\n |-- OTHER_POL_CMTE_CONTRIB: double (nullable = true)\n |-- POL_PTY_CONTRIB: double (nullable = true)\n |-- CVG_END_DT: date (nullable = true)\n |-- INDIV_REFUNDS: double (nullable = true)\n |-- CMTE_REFUNDS: double (nullable = true)\n |-- TOTAL_LOANS: double (nullable = true)\n |-- TOTAL_REPAY: double (nullable = true)\n |-- NET_RECEIPTS: double (nullable = true)\n |-- TOTAL_CONTRIB: double (nullable = true)\n\n+-------+---------+--------+------+--------------------+------------+---------------+--------+-------------+-------+-------+------------+----------+-----------+---------------+----------------+-------------+-----------------+--------------+--------------------+----------------------+---------------+----------+-------------+------------+-----------+-----------+------------+-------------+\n|CAND_ID|CAND_NAME|CAND_ICI|PTY_CD|CAND_PTY_AFFILIATION|TTL_RECEIPTS|TRANS_FROM_AUTH|TTL_DISB|TRANS_TO_AUTH|COH_BOP|COH_COP|CAND_CONTRIB|CAND_LOANS|OTHER_LOANS|CAND_LOAN_REPAY|OTHER_LOAN_REPAY|DEBTS_OWED_BY|TTL_INDIV_CONTRIB|CAND_OFFICE_ST|CAND_OFFICE_DISTRICT|OTHER_POL_CMTE_CONTRIB|POL_PTY_CONTRIB|CVG_END_DT|INDIV_REFUNDS|CMTE_REFUNDS|TOTAL_LOANS|TOTAL_REPAY|NET_RECEIPTS|TOTAL_CONTRIB|\n+-------+---------+--------+------+--------------------+------------+---------------+--------+-------------+-------+-------+------------+----------+-----------+---------------+----------------+-------------+-----------------+--------------+--------------------+----------------------+---------------+----------+-------------+------------+-----------+-----------+------------+-------------+\n|      0|        0|       0|     0|                   0|           0|              0|       0|            0|      0|      0|           0|         0|          0|              0|               0|            0|                0|             0|                   0|                     0|              0|         0|            0|           0|          0|          0|           0|            0|\n+-------+---------+--------+------+--------------------+------------+---------------+--------+-------------+-------+-------+------------+----------+-----------+---------------+----------------+-------------+-----------------+--------------+--------------------+----------------------+---------------+----------+-------------+------------+-----------+-----------+------------+-------------+\n\n"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/HouSenCurCam_df\"\nHouSenCurCam_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nHouSenCurCam_df.printSchema()\n\n# Check for null values\nnull_counts(HouSenCurCam_df).show()"}, {"cell_type": "markdown", "id": "9f81f976-5597-4f59-ae54-4501e8b8d225", "metadata": {}, "source": "### For Operating expenditures df"}, {"cell_type": "code", "execution_count": 50, "id": "a9cb7c87-8e40-41fe-b062-a9e19045e0f1", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/OpEx_df\n"}], "source": "# Operating expenditures\n\n# Clean data\nOpEx_df = base_clean(OpEx_df)\nOpEx_df = clean_OpEx_df(OpEx_df)\n\n#Type cast\nOpEx_df = typecast_OpEx_df(OpEx_df)\n\n# Feature Engineering\nOpEx_df = features_OpEx_df(OpEx_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(OpEx_df,'OpEx_df')\n"}, {"cell_type": "code", "execution_count": 51, "id": "fbbefb67-2b18-4ca4-bf0a-c0f6bd8b324a", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CMTE_ID: string (nullable = true)\n |-- AMNDT_IND: string (nullable = true)\n |-- RPT_YR: integer (nullable = true)\n |-- RPT_TP: string (nullable = true)\n |-- IMAGE_NUM: string (nullable = true)\n |-- LINE_NUM: string (nullable = true)\n |-- FORM_TP_CD: string (nullable = true)\n |-- SCHED_TP_CD: string (nullable = true)\n |-- NAME: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- STATE: string (nullable = true)\n |-- ZIP_CODE: string (nullable = true)\n |-- TRANSACTION_DT: date (nullable = true)\n |-- TRANSACTION_AMT: double (nullable = true)\n |-- TRANSACTION_PGI: string (nullable = true)\n |-- PURPOSE: string (nullable = true)\n |-- CATEGORY: string (nullable = true)\n |-- CATEGORY_DESC: string (nullable = true)\n |-- ENTITY_TP: string (nullable = true)\n |-- SUB_ID: long (nullable = true)\n |-- FILE_NUM: integer (nullable = true)\n |-- TRAN_ID: string (nullable = true)\n |-- YEAR: integer (nullable = true)\n |-- MONTH: integer (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 57:>                                                         (0 + 4) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+---------+------+------+---------+--------+----------+-----------+----+----+-----+--------+--------------+---------------+---------------+-------+--------+-------------+---------+------+--------+-------+----+-----+\n|CMTE_ID|AMNDT_IND|RPT_YR|RPT_TP|IMAGE_NUM|LINE_NUM|FORM_TP_CD|SCHED_TP_CD|NAME|CITY|STATE|ZIP_CODE|TRANSACTION_DT|TRANSACTION_AMT|TRANSACTION_PGI|PURPOSE|CATEGORY|CATEGORY_DESC|ENTITY_TP|SUB_ID|FILE_NUM|TRAN_ID|YEAR|MONTH|\n+-------+---------+------+------+---------+--------+----------+-----------+----+----+-----+--------+--------------+---------------+---------------+-------+--------+-------------+---------+------+--------+-------+----+-----+\n|      0|        0|     0|     0|        0|       0|         0|          0|   0|   0|    0|       0|             0|              0|              0|      0|       0|            0|        0|     0|       0|      0|   0|    0|\n+-------+---------+------+------+---------+--------+----------+-----------+----+----+-----+--------+--------------+---------------+---------------+-------+--------+-------------+---------+------+--------+-------+----+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/OpEx_df\"\nOpEx_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nOpEx_df.printSchema()\n\n# Check for null values\nnull_counts(OpEx_df).show()"}, {"cell_type": "markdown", "id": "8cb3ca12-0f91-4260-90c0-cc26bdcdd0ef", "metadata": {}, "source": "### For PAC summary df"}, {"cell_type": "code", "execution_count": 52, "id": "675da6b9-b6c4-4565-99a9-6aa9c4d89f54", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/PacSum_df\n"}], "source": "# PAC summary df\n\n# Clean data\nPacSum_df = base_clean(PacSum_df)\nPacSum_df = clean_PacSum_df(PacSum_df)\n\n#Type cast\nPacSum_df = typecast_PacSum_df(PacSum_df)\n\n# Feature Engineering\nPacSum_df = features_PacSum_df(PacSum_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(PacSum_df,'PacSum_df')\n"}, {"cell_type": "code", "execution_count": 53, "id": "f1c98e96-a53b-4ea2-84dd-cf1125b1b7f9", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CMTE_ID: string (nullable = true)\n |-- CMTE_NM: string (nullable = true)\n |-- CMTE_TP: string (nullable = true)\n |-- CMTE_FILING_FREQ: string (nullable = true)\n |-- TTL_RECEIPTS: double (nullable = true)\n |-- TRANS_FROM_AFF: double (nullable = true)\n |-- INDV_CONTRIB: double (nullable = true)\n |-- OTHER_POL_CMTE_CONTRIB: double (nullable = true)\n |-- TTL_DISB: double (nullable = true)\n |-- TRANF_TO_AFF: double (nullable = true)\n |-- LOAN_REPAY: double (nullable = true)\n |-- COH_BOP: double (nullable = true)\n |-- COH_COP: double (nullable = true)\n |-- DEBTS_OWED_BY: double (nullable = true)\n |-- CONTRIB_TO_OTHER_CMTE: double (nullable = true)\n |-- IND_EXP: double (nullable = true)\n |-- PTY_COORD_EXP: double (nullable = true)\n |-- CVG_END_DT: date (nullable = true)\n |-- NET_CASH_FLOW: double (nullable = true)\n |-- INDV_CONTRIB_RATIO: double (nullable = true)\n |-- YEAR: integer (nullable = true)\n\n+-------+-------+-------+----------------+------------+--------------+------------+----------------------+--------+------------+----------+-------+-------+-------------+---------------------+-------+-------------+----------+-------------+------------------+----+\n|CMTE_ID|CMTE_NM|CMTE_TP|CMTE_FILING_FREQ|TTL_RECEIPTS|TRANS_FROM_AFF|INDV_CONTRIB|OTHER_POL_CMTE_CONTRIB|TTL_DISB|TRANF_TO_AFF|LOAN_REPAY|COH_BOP|COH_COP|DEBTS_OWED_BY|CONTRIB_TO_OTHER_CMTE|IND_EXP|PTY_COORD_EXP|CVG_END_DT|NET_CASH_FLOW|INDV_CONTRIB_RATIO|YEAR|\n+-------+-------+-------+----------------+------------+--------------+------------+----------------------+--------+------------+----------+-------+-------+-------------+---------------------+-------+-------------+----------+-------------+------------------+----+\n|      0|      0|      0|               0|           0|             0|           0|                     0|       0|           0|         0|      0|      0|            0|                    0|      0|            0|         0|            0|                 0|   0|\n+-------+-------+-------+----------------+------------+--------------+------------+----------------------+--------+------------+----------+-------+-------+-------------+---------------------+-------+-------------+----------+-------------+------------------+----+\n\n"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/PacSum_df\"\nPacSum_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nPacSum_df.printSchema()\n\n# Check for null values\nnull_counts(PacSum_df).show()"}, {"cell_type": "markdown", "id": "4dfebfb6-5649-4bef-a656-7f529837de6c", "metadata": {}, "source": "### For Candidate master df"}, {"cell_type": "code", "execution_count": 54, "id": "4685197f-4543-4f3e-a448-3a1c963e052b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/CandMast_df\n"}], "source": "# Candidate master df\n\n# Clean data\nCandMast_df = base_clean(CandMast_df)\nCandMast_df = clean_CandMast_df(CandMast_df)\n\n#Type cast\nCandMast_df = typecast_CandMast_df(CandMast_df)\n\n# Feature Engineering\nCandMast_df = features_CandMast_df(CandMast_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(CandMast_df,'CandMast_df')\n"}, {"cell_type": "code", "execution_count": 55, "id": "e0a2ae8a-bfdc-4a36-9197-edc6ec7108b5", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CAND_ID: string (nullable = true)\n |-- CAND_NAME: string (nullable = true)\n |-- CAND_PTY_AFFILIATION: string (nullable = true)\n |-- CAND_ELECTION_YR: integer (nullable = true)\n |-- CAND_OFFICE_ST: string (nullable = true)\n |-- CAND_OFFICE: string (nullable = true)\n |-- CAND_OFFICE_DISTRICT: integer (nullable = true)\n |-- CAND_ICI: string (nullable = true)\n |-- CAND_STATUS: string (nullable = true)\n |-- CAND_CITY: string (nullable = true)\n |-- CAND_ST: string (nullable = true)\n |-- CAND_ZIP: string (nullable = true)\n |-- IS_INCUMBENT: integer (nullable = true)\n |-- IS_CHALLENGER: integer (nullable = true)\n |-- IS_OPEN_SEAT: integer (nullable = true)\n\n+-------+---------+--------------------+----------------+--------------+-----------+--------------------+--------+-----------+---------+-------+--------+------------+-------------+------------+\n|CAND_ID|CAND_NAME|CAND_PTY_AFFILIATION|CAND_ELECTION_YR|CAND_OFFICE_ST|CAND_OFFICE|CAND_OFFICE_DISTRICT|CAND_ICI|CAND_STATUS|CAND_CITY|CAND_ST|CAND_ZIP|IS_INCUMBENT|IS_CHALLENGER|IS_OPEN_SEAT|\n+-------+---------+--------------------+----------------+--------------+-----------+--------------------+--------+-----------+---------+-------+--------+------------+-------------+------------+\n|      0|        0|                   0|               0|             0|          0|                   0|       0|          0|        0|      0|       0|           0|            0|           0|\n+-------+---------+--------------------+----------------+--------------+-----------+--------------------+--------+-----------+---------+-------+--------+------------+-------------+------------+\n\n"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/CandMast_df\"\nCandMast_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nCandMast_df.printSchema()\n\n# Check for null values\nnull_counts(CandMast_df).show()"}, {"cell_type": "markdown", "id": "7acb37a6-2ae0-4cac-b3bd-97a4a2b1e2b4", "metadata": {}, "source": "### For Commitee master df"}, {"cell_type": "code", "execution_count": 56, "id": "02fe37f6-9b10-4ca2-a620-eb1e915cac2c", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Data written to: gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/CommMast_df\n"}], "source": "# Commitee master df\n\n# Clean data\nCommMast_df = base_clean(CommMast_df)\nCommMast_df = clean_CommMast_df(CommMast_df)\n\n# Feature Engineering\nCommMast_df = features_CommMast_df(CommMast_df)\n\n# Save Data in processed Layer \nwrite_df_to_parquet(CommMast_df,'CommMast_df')\n"}, {"cell_type": "code", "execution_count": 57, "id": "8f78c784-1aaf-4399-9f76-5433342304c7", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- CMTE_ID: string (nullable = true)\n |-- CMTE_NM: string (nullable = true)\n |-- TRES_NM: string (nullable = true)\n |-- CMTE_CITY: string (nullable = true)\n |-- CMTE_ST: string (nullable = true)\n |-- CMTE_ZIP: string (nullable = true)\n |-- CMTE_DSGN: string (nullable = true)\n |-- CMTE_TP: string (nullable = true)\n |-- CMTE_PTY_AFFILIATION: string (nullable = true)\n |-- CMTE_FILING_FREQ: string (nullable = true)\n |-- ORG_TP: string (nullable = true)\n |-- CONNECTED_ORG_NM: string (nullable = true)\n |-- CAND_ID: string (nullable = true)\n |-- IS_CAND_LINKED: integer (nullable = true)\n |-- IS_AUTH_CMTE: integer (nullable = true)\n |-- IS_PAC: integer (nullable = true)\n |-- IS_PARTY_CMTE: integer (nullable = true)\n\n+-------+-------+-------+---------+-------+--------+---------+-------+--------------------+----------------+------+----------------+-------+--------------+------------+------+-------------+\n|CMTE_ID|CMTE_NM|TRES_NM|CMTE_CITY|CMTE_ST|CMTE_ZIP|CMTE_DSGN|CMTE_TP|CMTE_PTY_AFFILIATION|CMTE_FILING_FREQ|ORG_TP|CONNECTED_ORG_NM|CAND_ID|IS_CAND_LINKED|IS_AUTH_CMTE|IS_PAC|IS_PARTY_CMTE|\n+-------+-------+-------+---------+-------+--------+---------+-------+--------------------+----------------+------+----------------+-------+--------------+------------+------+-------------+\n|      0|      0|      0|        0|      0|       0|        0|      0|                   0|               0|     0|               0|      0|             0|           0|     0|            0|\n+-------+-------+-------+---------+-------+--------+---------+-------+--------------------+----------------+------+----------------+-------+--------------+------------+------+-------------+\n\n"}], "source": "# Check data by reading back\npath=\"gs://dataproc-staging-us-central1-40371648517-ndvgfbwp/notebooks/jupyter/FEC-Campaign-Analysis/FEC-Data/silver/CommMast_df\"\nCommMast_df = spark.read.parquet(path)\n\n# Check Schema for correct dtypes\nCommMast_df.printSchema()\n\n# Check for null values\nnull_counts(CommMast_df).show()"}, {"cell_type": "markdown", "id": "03669507-2ce0-453a-a132-836744bd1c19", "metadata": {}, "source": "#### Stop the spark session"}, {"cell_type": "code", "execution_count": 58, "id": "93ea6549-2ee8-4735-baf5-318d40cb8995", "metadata": {"tags": []}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "5013689d-6f6b-4893-a806-5989c5e90905", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}